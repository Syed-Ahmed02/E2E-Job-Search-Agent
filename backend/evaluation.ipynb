{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Retrieval Quality Evaluation\n",
        "\n",
        "This notebook evaluates the retrieval quality of the job search system by measuring:\n",
        "- **Precision@10**: Fraction of retrieved documents that are relevant\n",
        "- **Recall@10/50**: Fraction of all relevant documents that were retrieved\n",
        "- **MRR (Mean Reciprocal Rank)**: Average reciprocal rank of first relevant result\n",
        "- **NDCG@10**: Normalized Discounted Cumulative Gain at rank 10\n",
        "\n",
        "## Dataset\n",
        "- ~60k jobs from azrai99/job-dataset on HuggingFace\n",
        "- 40+ synthetic queries covering various job categories, locations, and experience levels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import chromadb\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from dotenv import load_dotenv\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better-looking plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sanitize_metadata(metadata):\n",
        "    \"\"\"\n",
        "    Sanitize metadata to ensure all values are valid ChromaDB types.\n",
        "    ChromaDB accepts: str, int, float, bool, None\n",
        "    Converts None to empty string and ensures all values are valid types.\n",
        "    \"\"\"\n",
        "    sanitized = {}\n",
        "    for key, value in metadata.items():\n",
        "        if value is None:\n",
        "            sanitized[key] = \"\"  # Convert None to empty string\n",
        "        elif isinstance(value, (str, int, float, bool)):\n",
        "            sanitized[key] = value\n",
        "        elif isinstance(value, list):\n",
        "            # Convert lists to comma-separated string\n",
        "            sanitized[key] = \", \".join(str(v) for v in value if v is not None)\n",
        "        elif isinstance(value, dict):\n",
        "            # Convert dicts to JSON string\n",
        "            sanitized[key] = json.dumps(value)\n",
        "        else:\n",
        "            # Convert any other type to string\n",
        "            sanitized[key] = str(value) if value is not None else \"\"\n",
        "    return sanitized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vector_store_with_batching(client, documents, embeddings, collection_name, batch_size=100):\n",
        "    \"\"\"\n",
        "    Create vector store with batched uploads to prevent timeouts.\n",
        "    Uses incremental embedding and upload to handle large datasets.\n",
        "    \"\"\"\n",
        "    print(f\"\\n   Starting batched upload of {len(documents)} documents...\")\n",
        "    print(f\"   Batch size: {batch_size} documents per batch\")\n",
        "    \n",
        "    # Create empty collection first\n",
        "    try:\n",
        "        collection = client.create_collection(\n",
        "            name=collection_name,\n",
        "            metadata={\"description\": \"Evaluation job dataset\"}\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Collection might already exist\n",
        "        try:\n",
        "            collection = client.get_collection(name=collection_name)\n",
        "            print(f\"   Using existing collection: {collection_name}\")\n",
        "        except:\n",
        "            raise Exception(f\"Failed to create or get collection: {e}\")\n",
        "    \n",
        "    # Process documents in batches\n",
        "    total_batches = (len(documents) + batch_size - 1) // batch_size\n",
        "    \n",
        "    print(f\"   Processing {total_batches} batches...\")\n",
        "    \n",
        "    for batch_idx in range(total_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(documents))\n",
        "        batch_docs = documents[start_idx:end_idx]\n",
        "        \n",
        "        print(f\"   Batch {batch_idx + 1}/{total_batches}: Processing documents {start_idx + 1}-{end_idx}...\")\n",
        "        \n",
        "        # Prepare batch data\n",
        "        batch_ids = [f\"doc_{start_idx + i}\" for i in range(len(batch_docs))]\n",
        "        batch_texts = [doc.page_content for doc in batch_docs]\n",
        "        # Sanitize metadata to ensure all values are valid ChromaDB types\n",
        "        batch_metadatas = [sanitize_metadata(doc.metadata) for doc in batch_docs]\n",
        "        \n",
        "        # Generate embeddings for this batch\n",
        "        try:\n",
        "            batch_embeddings = embeddings.embed_documents(batch_texts)\n",
        "        except Exception as e:\n",
        "            print(f\"      Error embedding batch {batch_idx + 1}: {e}\")\n",
        "            # Retry once\n",
        "            time.sleep(2)\n",
        "            try:\n",
        "                batch_embeddings = embeddings.embed_documents(batch_texts)\n",
        "            except Exception as e2:\n",
        "                print(f\"      Failed to embed batch {batch_idx + 1} after retry. Skipping...\")\n",
        "                continue\n",
        "        \n",
        "        # Upload batch to ChromaDB with retry logic\n",
        "        max_retries = 3\n",
        "        retry_delay = 5\n",
        "        \n",
        "        for retry in range(max_retries):\n",
        "            try:\n",
        "                collection.add(\n",
        "                    ids=batch_ids,\n",
        "                    embeddings=batch_embeddings,\n",
        "                    documents=batch_texts,\n",
        "                    metadatas=batch_metadatas\n",
        "                )\n",
        "                print(f\"      ✓ Uploaded batch {batch_idx + 1}/{total_batches} ({len(batch_docs)} documents)\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                if retry < max_retries - 1:\n",
        "                    wait_time = retry_delay * (retry + 1)\n",
        "                    print(f\"      ⚠ Error uploading batch {batch_idx + 1} (attempt {retry + 1}/{max_retries}): {e}\")\n",
        "                    print(f\"      Retrying in {wait_time} seconds...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"      ✗ Failed to upload batch {batch_idx + 1} after {max_retries} attempts: {e}\")\n",
        "                    raise\n",
        "        \n",
        "        # Small delay between batches to avoid rate limiting\n",
        "        if batch_idx < total_batches - 1:\n",
        "            time.sleep(0.5)\n",
        "    \n",
        "    print(f\"\\n   ✓ Successfully uploaded all {len(documents)} documents to ChromaDB Cloud!\")\n",
        "    \n",
        "    # Create and return vector store\n",
        "    vector_store = Chroma(\n",
        "        client=client,\n",
        "        collection_name=collection_name,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "    \n",
        "    return vector_store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def extract_keywords(query):\n",
        "    \"\"\"Enhanced keyword extraction from query (removes stopwords, handles common job search terms)\"\"\"\n",
        "    stopwords = {\n",
        "        \"with\", \"and\", \"in\", \"for\", \"the\", \"a\", \"an\", \"of\", \"to\", \"experience\", \n",
        "        \"specializing\", \"skills\", \"position\", \"role\", \"job\", \"based\", \"own\"\n",
        "    }\n",
        "    # Remove punctuation and split\n",
        "    words = query.lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \" \").split()\n",
        "    keywords = [w for w in words if w not in stopwords and len(w) > 2]\n",
        "    return keywords\n",
        "\n",
        "def is_relevant(query, retrieved_doc):\n",
        "    \"\"\"\n",
        "    Enhanced heuristic to determine if a retrieved document is relevant to the query.\n",
        "    Checks title, description, category, subcategory, role, and location.\n",
        "    \"\"\"\n",
        "    keywords = extract_keywords(query)\n",
        "    \n",
        "    # Extract metadata fields (handle None values)\n",
        "    job_title = (retrieved_doc.metadata.get(\"job_title\") or \"\").lower()\n",
        "    job_desc = retrieved_doc.page_content.lower()[:1000]  # Check first 1000 chars\n",
        "    category = (retrieved_doc.metadata.get(\"category\") or \"\").lower()\n",
        "    subcategory = (retrieved_doc.metadata.get(\"subcategory\") or \"\").lower()\n",
        "    role = (retrieved_doc.metadata.get(\"role\") or \"\").lower()\n",
        "    location = (retrieved_doc.metadata.get(\"location\") or \"\").lower()\n",
        "    job_type = (retrieved_doc.metadata.get(\"type\") or \"\").lower()\n",
        "    \n",
        "    # Combine all text fields for matching\n",
        "    all_text = f\"{job_title} {category} {subcategory} {role} {location} {job_type} {job_desc}\"\n",
        "    \n",
        "    # 1. Title Match (Highest Confidence - exact role match)\n",
        "    title_matches = sum(1 for k in keywords if k in job_title)\n",
        "    if title_matches >= 2:  # At least 2 keywords in title\n",
        "        return True\n",
        "    if title_matches == 1 and len(keywords) <= 3:  # Single keyword match for short queries\n",
        "        return True\n",
        "    \n",
        "    # 2. Role/Category Match (High Confidence)\n",
        "    role_matches = sum(1 for k in keywords if k in role or k in subcategory)\n",
        "    if role_matches >= 2:\n",
        "        return True\n",
        "    \n",
        "    # 3. Location Match (if location is specified in query)\n",
        "    location_keywords = [k for k in keywords if any(loc in k for loc in [\"kuala\", \"lumpur\", \"selangor\", \"klang\", \"malaysia\", \"petaling\", \"jaya\"])]\n",
        "    if location_keywords and any(loc in all_text for loc in location_keywords):\n",
        "        location_match = True\n",
        "    else:\n",
        "        location_match = len(location_keywords) == 0  # No location requirement\n",
        "    \n",
        "    # 4. Description Match (Secondary - requires multiple keyword matches)\n",
        "    desc_matches = sum(1 for k in keywords if k in job_desc)\n",
        "    \n",
        "    # 5. Job Type Match (if specified)\n",
        "    type_keywords = [k for k in keywords if k in [\"full\", \"time\", \"contract\", \"temp\", \"part\"]]\n",
        "    type_match = len(type_keywords) == 0 or any(t in job_type for t in type_keywords)\n",
        "    \n",
        "    # Combined scoring: Require multiple matches across different fields\n",
        "    total_matches = title_matches + role_matches + desc_matches\n",
        "    \n",
        "    # Relevance criteria:\n",
        "    # - At least 3 total keyword matches AND location/type compatibility\n",
        "    # - OR at least 2 matches in title/role (high confidence fields)\n",
        "    if total_matches >= 3 and location_match and type_match:\n",
        "        return True\n",
        "    if (title_matches + role_matches) >= 2 and location_match:\n",
        "        return True\n",
        "        \n",
        "    return False\n",
        "\n",
        "def calculate_precision_at_k(relevant_docs, k):\n",
        "    \"\"\"Calculate Precision@K.\"\"\"\n",
        "    if k == 0: return 0.0\n",
        "    relevant_in_k = relevant_docs[:k]\n",
        "    return sum(relevant_in_k) / k\n",
        "\n",
        "def calculate_recall_at_k(relevant_docs, total_relevant_in_dataset, k):\n",
        "    \"\"\"Calculate Recall@K.\"\"\"\n",
        "    if total_relevant_in_dataset == 0: return 0.0\n",
        "    relevant_in_k = relevant_docs[:k]\n",
        "    return sum(relevant_in_k) / total_relevant_in_dataset\n",
        "\n",
        "def categorize_query(query):\n",
        "    \"\"\"Categorize query into a category for analysis.\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    if any(term in query_lower for term in ['developer', 'engineer', 'scientist', 'software', 'data', 'devops', 'python', 'javascript', 'react', 'node', 'tensorflow']):\n",
        "        return 'Technology'\n",
        "    elif any(term in query_lower for term in ['manager', 'executive', 'analyst', 'business', 'sales', 'marketing', 'product']):\n",
        "        return 'Business/Management'\n",
        "    elif any(term in query_lower for term in ['accountant', 'financial', 'audit', 'accounts', 'cpa']):\n",
        "        return 'Finance/Accounting'\n",
        "    elif any(term in query_lower for term in ['procurement', 'supply chain', 'logistics', 'purchasing', 'inventory']):\n",
        "        return 'Supply Chain'\n",
        "    elif any(term in query_lower for term in ['hr', 'human resources', 'recruitment', 'talent', 'administrative', 'executive assistant']):\n",
        "        return 'HR/Administration'\n",
        "    elif any(term in query_lower for term in ['customer', 'support', 'service', 'representative']):\n",
        "        return 'Customer Service'\n",
        "    elif any(term in query_lower for term in ['kuala lumpur', 'selangor', 'petaling', 'klang', 'malaysia']):\n",
        "        return 'Location-Specific'\n",
        "    elif any(term in query_lower for term in ['full-time', 'contract', 'part-time', 'temp']):\n",
        "        return 'Job Type-Specific'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "print(\"✓ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RAG Retrieval Quality Evaluation ===\n",
            "\n",
            "1. Loading dataset...\n",
            "   Loaded 59306 jobs from azrai99/job-dataset.\n",
            "   Dataset fields: ['job_id', 'job_title', 'company', 'descriptions', 'location', 'category', 'subcategory', 'role', 'type', 'salary', 'listingDate']\n",
            "   This may take several minutes to process all jobs...\n"
          ]
        }
      ],
      "source": [
        "print(\"=== RAG Retrieval Quality Evaluation ===\\n\")\n",
        "\n",
        "# 1. Load and Prepare Dataset\n",
        "print(\"1. Loading dataset...\")\n",
        "try:\n",
        "    # Load the azrai99/job-dataset from HuggingFace (all ~60k jobs)\n",
        "    dataset = load_dataset(\"azrai99/job-dataset\", split=\"train\")\n",
        "    \n",
        "    print(f\"   Loaded {len(dataset)} jobs from azrai99/job-dataset.\")\n",
        "    print(f\"   Dataset fields: {list(dataset[0].keys())}\")\n",
        "    print(f\"   This may take several minutes to process all jobs...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   Error loading dataset: {e}\")\n",
        "    raise  # Re-raise the error since we need the full dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Embeddings and Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2. Initializing Vector Store...\n",
            "   Processing and preparing documents for vector store...\n",
            "   Processed 5000/59306 documents...\n",
            "   Processed 10000/59306 documents...\n",
            "   Processed 15000/59306 documents...\n",
            "   Processed 20000/59306 documents...\n",
            "   Processed 25000/59306 documents...\n",
            "   Processed 30000/59306 documents...\n",
            "   Processed 35000/59306 documents...\n",
            "   Processed 40000/59306 documents...\n",
            "   Processed 45000/59306 documents...\n",
            "   Processed 50000/59306 documents...\n",
            "   Processed 55000/59306 documents...\n",
            "   Prepared 59306 documents for ingestion.\n"
          ]
        }
      ],
      "source": [
        "# 2. Initialize Embeddings and Vector Store\n",
        "print(\"\\n2. Initializing Vector Store...\")\n",
        "\n",
        "# Initialize Embeddings (matching production setup)\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={'device': 'cpu'}\n",
        ")\n",
        "\n",
        "# Prepare documents for ingestion\n",
        "print(\"   Processing and preparing documents for vector store...\")\n",
        "documents = []\n",
        "total_items = len(dataset)\n",
        "for idx, item in enumerate(dataset):\n",
        "    if (idx + 1) % 5000 == 0:\n",
        "        print(f\"   Processed {idx + 1}/{total_items} documents...\")\n",
        "    # Extract fields based on azrai99/job-dataset structure\n",
        "    content = item.get(\"descriptions\", \"\") or item.get(\"description\", \"\")\n",
        "    title = item.get(\"job_title\", \"\") or item.get(\"title\", \"\")\n",
        "    company = item.get(\"company\", \"\") or item.get(\"company_name\", \"\")\n",
        "    location = item.get(\"location\", \"\")\n",
        "    category = item.get(\"category\", \"\")\n",
        "    subcategory = item.get(\"subcategory\", \"\")\n",
        "    role = item.get(\"role\", \"\")\n",
        "    job_type = item.get(\"type\", \"\")\n",
        "    \n",
        "    if content:\n",
        "        doc = Document(\n",
        "            page_content=content,\n",
        "            metadata={\n",
        "                \"job_title\": title,\n",
        "                \"company\": company,\n",
        "                \"location\": location,\n",
        "                \"category\": category,\n",
        "                \"subcategory\": subcategory,\n",
        "                \"role\": role,\n",
        "                \"type\": job_type\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "print(f\"   Prepared {len(documents)} documents for ingestion.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Connecting to ChromaDB Cloud...\n",
            "   Using collection: evaluation_jobs\n",
            "   Found existing collection with 59306 documents.\n",
            "   Collection already has all documents. Using existing collection.\n",
            "   Vector Store initialized and populated.\n"
          ]
        }
      ],
      "source": [
        "# Connect to ChromaDB Cloud\n",
        "chroma_api_key = os.getenv(\"CHROMA_API_KEY\")\n",
        "if not chroma_api_key:\n",
        "    raise ValueError(\"CHROMA_API_KEY environment variable must be set in .env file\")\n",
        "\n",
        "print(\"   Connecting to ChromaDB Cloud...\")\n",
        "client = chromadb.CloudClient(\n",
        "    api_key=chroma_api_key,\n",
        "    tenant='361f16d2-3a10-4479-854c-519de88ae973',\n",
        "    database='job_search_db'\n",
        "    )\n",
        "\n",
        "# Create or get collection\n",
        "collection_name = \"evaluation_jobs\"\n",
        "print(f\"   Using collection: {collection_name}\")\n",
        "\n",
        "# Check if collection exists and get count\n",
        "try:\n",
        "    existing_collection = client.get_collection(name=collection_name)\n",
        "    existing_count = existing_collection.count()\n",
        "    print(f\"   Found existing collection with {existing_count} documents.\")\n",
        "    \n",
        "    if existing_count == len(documents):\n",
        "        print(\"   Collection already has all documents. Using existing collection.\")\n",
        "        vector_store = Chroma(\n",
        "    client=client,\n",
        "            collection_name=collection_name,\n",
        "            embedding_function=embeddings\n",
        "        )\n",
        "    else:\n",
        "        print(f\"   Collection has {existing_count} documents, need {len(documents)}. Will recreate for clean evaluation.\")\n",
        "        # Delete and recreate for clean evaluation\n",
        "        try:\n",
        "            client.delete_collection(name=collection_name)\n",
        "            print(\"   Deleted existing collection for fresh evaluation.\")\n",
        "        except Exception as del_e:\n",
        "            print(f\"   Warning: Could not delete collection: {del_e}\")\n",
        "        vector_store = create_vector_store_with_batching(\n",
        "            client, documents, embeddings, collection_name\n",
        "        )\n",
        "except chromadb.errors.NotFoundError:\n",
        "    # Collection doesn't exist - create it\n",
        "    print(\"   Collection doesn't exist. Creating new collection with batched upload...\")\n",
        "    vector_store = create_vector_store_with_batching(\n",
        "        client, documents, embeddings, collection_name\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"   Error checking collection: {e}\")\n",
        "    print(\"   Attempting to create new collection with batched upload...\")\n",
        "    vector_store = create_vector_store_with_batching(\n",
        "        client, documents, embeddings, collection_name\n",
        "    )\n",
        "\n",
        "print(\"   Vector Store initialized and populated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3. Defined 43 comprehensive synthetic queries for evaluation.\n",
            "   Query categories: Technology, Business, Finance, Sales, Supply Chain, HR, Engineering, Customer Service, Location-specific, Job Type-specific, Multi-criteria\n"
          ]
        }
      ],
      "source": [
        "# 3. Define Comprehensive Synthetic User Personas/Queries\n",
        "# These queries test various aspects: experience levels, industries, locations, skills, job types\n",
        "synthetic_queries = [\n",
        "    # Technology & Software Development\n",
        "    \"Senior Python Developer with Flask and AWS cloud experience\",\n",
        "    \"Junior Software Engineer with React and JavaScript skills\",\n",
        "    \"Full Stack Developer with Node.js and MongoDB experience\",\n",
        "    \"DevOps Engineer with Kubernetes, Docker, and CI/CD pipeline expertise\",\n",
        "    \"Data Scientist specializing in machine learning and TensorFlow\",\n",
        "    \n",
        "    # Business & Management\n",
        "    \"Project Manager for construction and infrastructure projects\",\n",
        "    \"Account Executive with B2B sales experience in technology sector\",\n",
        "    \"Business Analyst with data analysis and SQL skills\",\n",
        "    \"Operations Manager for supply chain and logistics\",\n",
        "    \"Product Manager with agile methodology experience\",\n",
        "    \n",
        "    # Finance & Accounting\n",
        "    \"Accountant with CPA certification and financial reporting experience\",\n",
        "    \"Financial Analyst with Excel and financial modeling skills\",\n",
        "    \"Accounts Executive for accounts payable and receivable management\",\n",
        "    \"Audit Assistant with accounting degree and audit experience\",\n",
        "    \n",
        "    # Sales & Marketing\n",
        "    \"Sales Representative for medical devices and healthcare products\",\n",
        "    \"Marketing Manager with digital marketing and social media experience\",\n",
        "    \"Business Development Executive for B2B client acquisition\",\n",
        "    \"Customer Relationship Manager with account management skills\",\n",
        "    \n",
        "    # Supply Chain & Procurement\n",
        "    \"Procurement Executive with contract management and supplier relations\",\n",
        "    \"Supply Chain Planner with inventory management and forecasting\",\n",
        "    \"Logistics Coordinator for warehouse and distribution operations\",\n",
        "    \"Purchasing Officer with vendor management experience\",\n",
        "    \n",
        "    # Human Resources & Administration\n",
        "    \"Human Resources Specialist for recruitment and employee relations\",\n",
        "    \"HR Executive with talent acquisition and onboarding experience\",\n",
        "    \"Administrative Assistant with office management skills\",\n",
        "    \"Executive Assistant with calendar management and travel coordination\",\n",
        "    \n",
        "    # Engineering & Manufacturing\n",
        "    \"Mechanical Engineer with CAD design and manufacturing experience\",\n",
        "    \"Quality Assurance Engineer with testing and quality control\",\n",
        "    \"Production Supervisor for manufacturing operations\",\n",
        "    \n",
        "    # Customer Service & Support\n",
        "    \"Customer Support Agent bilingual in English and Spanish\",\n",
        "    \"Customer Service Representative with call center experience\",\n",
        "    \"Technical Support Specialist with troubleshooting skills\",\n",
        "    \n",
        "    # Location-Specific Queries (Malaysia-focused based on dataset)\n",
        "    \"Software Developer position in Kuala Lumpur\",\n",
        "    \"Sales Manager job in Selangor\",\n",
        "    \"Accountant role in Petaling Jaya\",\n",
        "    \n",
        "    # Job Type Specific\n",
        "    \"Full-time Marketing Executive position\",\n",
        "    \"Contract-based Project Manager role\",\n",
        "    \"Part-time Customer Service position\",\n",
        "    \n",
        "    # Multi-Criteria Complex Queries\n",
        "    \"Senior Data Analyst with Python, SQL, and Tableau experience in Kuala Lumpur\",\n",
        "    \"Junior Account Executive with sales experience and own transport in Klang\",\n",
        "    \"Procurement Manager with supply chain experience and contract negotiation skills\",\n",
        "    \"HR Manager with recruitment experience for tech startup in Malaysia\",\n",
        "    \"Supply Chain Planning role with inventory management and S&OP experience\"\n",
        "]\n",
        "\n",
        "print(f\"\\n3. Defined {len(synthetic_queries)} comprehensive synthetic queries for evaluation.\")\n",
        "print(\"   Query categories: Technology, Business, Finance, Sales, Supply Chain, HR, Engineering, Customer Service, Location-specific, Job Type-specific, Multi-criteria\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4. Running evaluation with K=10 (and K=50 for recall)...\n",
            "   Processing query 1/43: 'Senior Python Developer with Flask and AWS cloud experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 1792 relevant jobs in dataset.\n",
            "   Processing query 2/43: 'Junior Software Engineer with React and JavaScript skills'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 8388 relevant jobs in dataset.\n",
            "   Processing query 3/43: 'Full Stack Developer with Node.js and MongoDB experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 1384 relevant jobs in dataset.\n",
            "   Processing query 4/43: 'DevOps Engineer with Kubernetes, Docker, and CI/CD pipeline expertise'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 7575 relevant jobs in dataset.\n",
            "   Processing query 5/43: 'Data Scientist specializing in machine learning and TensorFlow'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 778 relevant jobs in dataset.\n",
            "   Processing query 6/43: 'Project Manager for construction and infrastructure projects'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 10707 relevant jobs in dataset.\n",
            "   Processing query 7/43: 'Account Executive with B2B sales experience in technology sector'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 21233 relevant jobs in dataset.\n",
            "   Processing query 8/43: 'Business Analyst with data analysis and SQL skills'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 4759 relevant jobs in dataset.\n",
            "   Processing query 9/43: 'Operations Manager for supply chain and logistics'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 8846 relevant jobs in dataset.\n",
            "   Processing query 10/43: 'Product Manager with agile methodology experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 8553 relevant jobs in dataset.\n",
            "   Processing query 11/43: 'Accountant with CPA certification and financial reporting experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 3762 relevant jobs in dataset.\n",
            "   Processing query 12/43: 'Financial Analyst with Excel and financial modeling skills'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 6242 relevant jobs in dataset.\n",
            "   Processing query 13/43: 'Accounts Executive for accounts payable and receivable management'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 18633 relevant jobs in dataset.\n",
            "   Processing query 14/43: 'Audit Assistant with accounting degree and audit experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 11036 relevant jobs in dataset.\n",
            "   Processing query 15/43: 'Sales Representative for medical devices and healthcare products'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n",
            "         Scanned 10000/59306 documents...\n",
            "         Scanned 20000/59306 documents...\n",
            "         Scanned 30000/59306 documents...\n",
            "         Scanned 40000/59306 documents...\n",
            "         Scanned 50000/59306 documents...\n",
            "      Found 5486 relevant jobs in dataset.\n",
            "   Processing query 16/43: 'Marketing Manager with digital marketing and social media experience'...\n",
            "      Calculating total relevant jobs in dataset (scanning 59306 documents)...\n"
          ]
        }
      ],
      "source": [
        "# 4. Run Evaluation Experiment\n",
        "results = []\n",
        "K = 10\n",
        "K_LARGE = 50  # For better recall evaluation\n",
        "\n",
        "print(f\"\\n4. Running evaluation with K={K} (and K={K_LARGE} for recall)...\")\n",
        "\n",
        "for query_idx, query in enumerate(synthetic_queries, 1):\n",
        "    print(f\"   Processing query {query_idx}/{len(synthetic_queries)}: '{query}'...\")\n",
        "    \n",
        "    # Retrieve Documents (retrieve more for better recall calculation)\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=K_LARGE)\n",
        "    \n",
        "    # Determine Relevance (Ground Truth) for top K_LARGE\n",
        "    relevance_mask = [is_relevant(query, doc) for doc in retrieved_docs]\n",
        "    \n",
        "    # Calculate Total Relevant in Dataset (for Recall)\n",
        "    # Note: This scans all documents - with 60k jobs this may take a few minutes per query\n",
        "    print(f\"      Calculating total relevant jobs in dataset (scanning {len(documents)} documents)...\")\n",
        "    total_relevant = 0\n",
        "    for doc_idx, doc in enumerate(documents):\n",
        "        if (doc_idx + 1) % 10000 == 0:\n",
        "            print(f\"         Scanned {doc_idx + 1}/{len(documents)} documents...\")\n",
        "        if is_relevant(query, doc):\n",
        "            total_relevant += 1\n",
        "    print(f\"      Found {total_relevant} relevant jobs in dataset.\")\n",
        "    \n",
        "    # Calculate metrics at different K values\n",
        "    p_at_10 = calculate_precision_at_k(relevance_mask, 10)\n",
        "    r_at_10 = calculate_recall_at_k(relevance_mask, total_relevant, 10)\n",
        "    r_at_50 = calculate_recall_at_k(relevance_mask, total_relevant, 50)\n",
        "    \n",
        "    # Calculate MRR (Mean Reciprocal Rank) - position of first relevant result\n",
        "    mrr = 0.0\n",
        "    for rank, is_rel in enumerate(relevance_mask, 1):\n",
        "        if is_rel:\n",
        "            mrr = 1.0 / rank\n",
        "            break\n",
        "    \n",
        "    # Calculate NDCG@10 (simplified - treating relevance as binary)\n",
        "    # NDCG = DCG / IDCG, where DCG = sum(rel_i / log2(i+1))\n",
        "    dcg = sum((1.0 if rel else 0.0) / np.log2(i + 2) for i, rel in enumerate(relevance_mask[:10]))\n",
        "    # IDCG: ideal case where all top 10 are relevant\n",
        "    idcg = sum(1.0 / np.log2(i + 2) for i in range(min(10, total_relevant)))\n",
        "    ndcg_at_10 = dcg / idcg if idcg > 0 else 0.0\n",
        "    \n",
        "    results.append({\n",
        "        \"Query\": query,\n",
        "        \"Precision@10\": p_at_10,\n",
        "        \"Recall@10\": r_at_10,\n",
        "        \"Recall@50\": r_at_50,\n",
        "        \"MRR\": mrr,\n",
        "        \"NDCG@10\": ndcg_at_10,\n",
        "        \"Total Relevant Found (top 10)\": sum(relevance_mask[:10]),\n",
        "        \"Total Relevant Found (top 50)\": sum(relevance_mask[:50]),\n",
        "        \"Total Relevant Exist\": total_relevant,\n",
        "        \"Top Match\": retrieved_docs[0].metadata.get(\"job_title\", \"N/A\") if retrieved_docs else \"N/A\"\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Results Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Results and Visualization\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Calculate Averages\n",
        "avg_precision = df_results[\"Precision@10\"].mean()\n",
        "avg_recall_10 = df_results[\"Recall@10\"].mean()\n",
        "avg_recall_50 = df_results[\"Recall@50\"].mean()\n",
        "avg_mrr = df_results[\"MRR\"].mean()\n",
        "avg_ndcg = df_results[\"NDCG@10\"].mean()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RETRIEVAL EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Average Precision@10:     {avg_precision:.4f} ({avg_precision*100:.2f}%)\")\n",
        "print(f\"Average Recall@10:        {avg_recall_10:.4f} ({avg_recall_10*100:.2f}%)\")\n",
        "print(f\"Average Recall@50:        {avg_recall_50:.4f} ({avg_recall_50*100:.2f}%)\")\n",
        "print(f\"Average MRR:              {avg_mrr:.4f}\")\n",
        "print(f\"Average NDCG@10:          {avg_ndcg:.4f}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Additional statistics\n",
        "print(\"\\nAdditional Statistics:\")\n",
        "print(f\"Queries with Perfect Precision@10: {sum(df_results['Precision@10'] == 1.0)}/{len(df_results)}\")\n",
        "print(f\"Queries with Zero Precision@10:    {sum(df_results['Precision@10'] == 0.0)}/{len(df_results)}\")\n",
        "print(f\"Median Precision@10:               {df_results['Precision@10'].median():.4f}\")\n",
        "print(f\"Median Recall@50:                  {df_results['Recall@50'].median():.4f}\")\n",
        "\n",
        "# Category analysis (if we can infer categories from queries)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Performance by Query Type:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Group by query characteristics\n",
        "tech_queries = df_results[df_results['Query'].str.contains('Developer|Engineer|Scientist|Software|Data|DevOps', case=False, na=False)]\n",
        "business_queries = df_results[df_results['Query'].str.contains('Manager|Executive|Analyst|Business|Sales|Marketing', case=False, na=False)]\n",
        "location_queries = df_results[df_results['Query'].str.contains('Kuala Lumpur|Selangor|Petaling|Klang|Malaysia', case=False, na=False)]\n",
        "\n",
        "if len(tech_queries) > 0:\n",
        "    print(f\"\\nTechnology/Engineering Queries ({len(tech_queries)} queries):\")\n",
        "    print(f\"  Avg Precision@10: {tech_queries['Precision@10'].mean():.4f}\")\n",
        "    print(f\"  Avg Recall@50:    {tech_queries['Recall@50'].mean():.4f}\")\n",
        "    print(f\"  Avg MRR:          {tech_queries['MRR'].mean():.4f}\")\n",
        "\n",
        "if len(business_queries) > 0:\n",
        "    print(f\"\\nBusiness/Management Queries ({len(business_queries)} queries):\")\n",
        "    print(f\"  Avg Precision@10: {business_queries['Precision@10'].mean():.4f}\")\n",
        "    print(f\"  Avg Recall@50:    {business_queries['Recall@50'].mean():.4f}\")\n",
        "    print(f\"  Avg MRR:          {business_queries['MRR'].mean():.4f}\")\n",
        "\n",
        "if len(location_queries) > 0:\n",
        "    print(f\"\\nLocation-Specific Queries ({len(location_queries)} queries):\")\n",
        "    print(f\"  Avg Precision@10: {location_queries['Precision@10'].mean():.4f}\")\n",
        "    print(f\"  Avg Recall@50:    {location_queries['Recall@50'].mean():.4f}\")\n",
        "    print(f\"  Avg MRR:          {location_queries['MRR'].mean():.4f}\")\n",
        "\n",
        "# Display DataFrame\n",
        "pd.set_option('display.max_colwidth', 40)\n",
        "pd.set_option('display.width', 1200)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Detailed Query Performance:\")\n",
        "print(\"=\"*70)\n",
        "display_cols = [\"Query\", \"Precision@10\", \"Recall@10\", \"Recall@50\", \"MRR\", \"NDCG@10\", \n",
        "                \"Total Relevant Found (top 10)\", \"Total Relevant Exist\"]\n",
        "print(df_results[display_cols].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generate Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Generate Visualizations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Generating visualizations...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create output directory for charts\n",
        "output_dir = Path(\"evaluation_results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Add query categories for better visualization\n",
        "df_results['Category'] = df_results['Query'].apply(categorize_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Precision@10 and Recall@50 Comparison Bar Chart\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "x_pos = np.arange(len(df_results))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x_pos, df_results['Precision@10'], width, label='Precision@10', alpha=0.8)\n",
        "ax1.axhline(y=avg_precision, color='r', linestyle='--', label=f'Average: {avg_precision:.3f}')\n",
        "ax1.set_xlabel('Query Index', fontsize=12)\n",
        "ax1.set_ylabel('Precision@10', fontsize=12)\n",
        "ax1.set_title('Precision@10 by Query', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x_pos[::5])  # Show every 5th query\n",
        "ax1.set_xticklabels([f'Q{i+1}' for i in x_pos[::5]], rotation=45, ha='right')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([0, 1.1])\n",
        "\n",
        "ax2.bar(x_pos, df_results['Recall@50'], width, label='Recall@50', alpha=0.8, color='orange')\n",
        "ax2.axhline(y=avg_recall_50, color='r', linestyle='--', label=f'Average: {avg_recall_50:.3f}')\n",
        "ax2.set_xlabel('Query Index', fontsize=12)\n",
        "ax2.set_ylabel('Recall@50', fontsize=12)\n",
        "ax2.set_title('Recall@50 by Query', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x_pos[::5])\n",
        "ax2.set_xticklabels([f'Q{i+1}' for i in x_pos[::5]], rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'precision_recall_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'precision_recall_comparison.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. MRR and NDCG@10 Comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "ax1.bar(x_pos, df_results['MRR'], width, label='MRR', alpha=0.8, color='green')\n",
        "ax1.axhline(y=avg_mrr, color='r', linestyle='--', label=f'Average: {avg_mrr:.3f}')\n",
        "ax1.set_xlabel('Query Index', fontsize=12)\n",
        "ax1.set_ylabel('MRR', fontsize=12)\n",
        "ax1.set_title('Mean Reciprocal Rank (MRR) by Query', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x_pos[::5])\n",
        "ax1.set_xticklabels([f'Q{i+1}' for i in x_pos[::5]], rotation=45, ha='right')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([0, 1.1])\n",
        "\n",
        "ax2.bar(x_pos, df_results['NDCG@10'], width, label='NDCG@10', alpha=0.8, color='purple')\n",
        "ax2.axhline(y=avg_ndcg, color='r', linestyle='--', label=f'Average: {avg_ndcg:.3f}')\n",
        "ax2.set_xlabel('Query Index', fontsize=12)\n",
        "ax2.set_ylabel('NDCG@10', fontsize=12)\n",
        "ax2.set_title('NDCG@10 by Query', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x_pos[::5])\n",
        "ax2.set_xticklabels([f'Q{i+1}' for i in x_pos[::5]], rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([0, 1.1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'mrr_ndcg_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'mrr_ndcg_comparison.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Precision vs Recall Scatter Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "scatter = ax.scatter(df_results['Recall@50'], df_results['Precision@10'], \n",
        "                    c=df_results['MRR'], s=100, alpha=0.6, cmap='viridis')\n",
        "ax.set_xlabel('Recall@50', fontsize=12)\n",
        "ax.set_ylabel('Precision@10', fontsize=12)\n",
        "ax.set_title('Precision@10 vs Recall@50 (colored by MRR)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(scatter, ax=ax)\n",
        "cbar.set_label('MRR', fontsize=12)\n",
        "\n",
        "# Add average lines\n",
        "ax.axhline(y=avg_precision, color='r', linestyle='--', alpha=0.5, label=f'Avg Precision: {avg_precision:.3f}')\n",
        "ax.axvline(x=avg_recall_50, color='r', linestyle='--', alpha=0.5, label=f'Avg Recall: {avg_recall_50:.3f}')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'precision_vs_recall_scatter.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'precision_vs_recall_scatter.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Category-wise Performance Comparison\n",
        "if df_results['Category'].nunique() > 1:\n",
        "    category_metrics = df_results.groupby('Category').agg({\n",
        "        'Precision@10': 'mean',\n",
        "        'Recall@50': 'mean',\n",
        "        'MRR': 'mean',\n",
        "        'NDCG@10': 'mean'\n",
        "    }).round(4)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    x = np.arange(len(category_metrics))\n",
        "    width = 0.2\n",
        "    \n",
        "    ax.bar(x - 1.5*width, category_metrics['Precision@10'], width, label='Precision@10', alpha=0.8)\n",
        "    ax.bar(x - 0.5*width, category_metrics['Recall@50'], width, label='Recall@50', alpha=0.8)\n",
        "    ax.bar(x + 0.5*width, category_metrics['MRR'], width, label='MRR', alpha=0.8)\n",
        "    ax.bar(x + 1.5*width, category_metrics['NDCG@10'], width, label='NDCG@10', alpha=0.8)\n",
        "    \n",
        "    ax.set_xlabel('Query Category', fontsize=12)\n",
        "    ax.set_ylabel('Score', fontsize=12)\n",
        "    ax.set_title('Average Performance Metrics by Query Category', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(category_metrics.index, rotation=45, ha='right')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.set_ylim([0, 1.1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir / 'category_performance.png', dpi=300, bbox_inches='tight')\n",
        "    print(f\"   Saved: {output_dir / 'category_performance.png'}\")\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Distribution of Metrics (Histograms)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "axes[0, 0].hist(df_results['Precision@10'], bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
        "axes[0, 0].axvline(avg_precision, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_precision:.3f}')\n",
        "axes[0, 0].set_xlabel('Precision@10', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 0].set_title('Distribution of Precision@10', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].hist(df_results['Recall@50'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
        "axes[0, 1].axvline(avg_recall_50, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_recall_50:.3f}')\n",
        "axes[0, 1].set_xlabel('Recall@50', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 1].set_title('Distribution of Recall@50', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].hist(df_results['MRR'], bins=20, alpha=0.7, color='green', edgecolor='black')\n",
        "axes[1, 0].axvline(avg_mrr, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_mrr:.3f}')\n",
        "axes[1, 0].set_xlabel('MRR', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1, 0].set_title('Distribution of MRR', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].hist(df_results['NDCG@10'], bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
        "axes[1, 1].axvline(avg_ndcg, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_ndcg:.3f}')\n",
        "axes[1, 1].set_xlabel('NDCG@10', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1, 1].set_title('Distribution of NDCG@10', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'metric_distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'metric_distributions.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Correlation Heatmap\n",
        "metric_cols = ['Precision@10', 'Recall@10', 'Recall@50', 'MRR', 'NDCG@10']\n",
        "corr_matrix = df_results[metric_cols].corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
        "ax.set_title('Correlation Matrix of Evaluation Metrics', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'correlation_heatmap.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Summary Statistics Table Visualization\n",
        "summary_stats = pd.DataFrame({\n",
        "    'Metric': ['Precision@10', 'Recall@10', 'Recall@50', 'MRR', 'NDCG@10'],\n",
        "    'Mean': [avg_precision, avg_recall_10, avg_recall_50, avg_mrr, avg_ndcg],\n",
        "    'Median': [\n",
        "        df_results['Precision@10'].median(),\n",
        "        df_results['Recall@10'].median(),\n",
        "        df_results['Recall@50'].median(),\n",
        "        df_results['MRR'].median(),\n",
        "        df_results['NDCG@10'].median()\n",
        "    ],\n",
        "    'Std Dev': [\n",
        "        df_results['Precision@10'].std(),\n",
        "        df_results['Recall@10'].std(),\n",
        "        df_results['Recall@50'].std(),\n",
        "        df_results['MRR'].std(),\n",
        "        df_results['NDCG@10'].std()\n",
        "    ],\n",
        "    'Min': [\n",
        "        df_results['Precision@10'].min(),\n",
        "        df_results['Recall@10'].min(),\n",
        "        df_results['Recall@50'].min(),\n",
        "        df_results['MRR'].min(),\n",
        "        df_results['NDCG@10'].min()\n",
        "    ],\n",
        "    'Max': [\n",
        "        df_results['Precision@10'].max(),\n",
        "        df_results['Recall@10'].max(),\n",
        "        df_results['Recall@50'].max(),\n",
        "        df_results['MRR'].max(),\n",
        "        df_results['NDCG@10'].max()\n",
        "    ]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "table = ax.table(cellText=summary_stats.round(4).values,\n",
        "                 colLabels=summary_stats.columns,\n",
        "                 cellLoc='center',\n",
        "                 loc='center',\n",
        "                 bbox=[0, 0, 1, 1])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.5)\n",
        "\n",
        "# Style the header\n",
        "for i in range(len(summary_stats.columns)):\n",
        "    table[(0, i)].set_facecolor('#40466e')\n",
        "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "ax.set_title('Summary Statistics of Evaluation Metrics', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.savefig(output_dir / 'summary_statistics.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'summary_statistics.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Top and Bottom Performing Queries\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Top 10 by Precision@10\n",
        "top_queries = df_results.nlargest(10, 'Precision@10')\n",
        "ax1.barh(range(len(top_queries)), top_queries['Precision@10'], alpha=0.8, color='green')\n",
        "ax1.set_yticks(range(len(top_queries)))\n",
        "ax1.set_yticklabels([f\"Q{i+1}\" for i in top_queries.index], fontsize=9)\n",
        "ax1.set_xlabel('Precision@10', fontsize=12)\n",
        "ax1.set_title('Top 10 Queries by Precision@10', fontsize=13, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "ax1.set_xlim([0, 1.1])\n",
        "\n",
        "# Bottom 10 by Precision@10\n",
        "bottom_queries = df_results.nsmallest(10, 'Precision@10')\n",
        "ax2.barh(range(len(bottom_queries)), bottom_queries['Precision@10'], alpha=0.8, color='red')\n",
        "ax2.set_yticks(range(len(bottom_queries)))\n",
        "ax2.set_yticklabels([f\"Q{i+1}\" for i in bottom_queries.index], fontsize=9)\n",
        "ax2.set_xlabel('Precision@10', fontsize=12)\n",
        "ax2.set_title('Bottom 10 Queries by Precision@10', fontsize=13, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='x')\n",
        "ax2.set_xlim([0, 1.1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'top_bottom_queries.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   Saved: {output_dir / 'top_bottom_queries.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Save results to CSV\n",
        "df_results.to_csv(output_dir / 'evaluation_results.csv', index=False)\n",
        "print(f\"   Saved: {output_dir / 'evaluation_results.csv'}\")\n",
        "\n",
        "print(f\"\\n✓ All visualizations saved to '{output_dir}/' directory\")\n",
        "print(f\"✓ Total files generated: 8 charts + 1 CSV file\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
